{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edd3cb3-b5c7-47c4-b05e-a78c4ddff2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pywinauto.application import Application\n",
    "import pyautogui\n",
    "import pytesseract\n",
    "import re\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ae53b-5909-478d-8b2b-33a92a5df74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef4999-872c-49a3-a5b7-8c92eb2c2539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pygetwindow pywinauto pytesseract numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2f580-778a-46ad-b0ba-ab516d470c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "# import pillow\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90d633-44f1-4bb6-8c1b-fb9139d28bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def navigate_to_fm_window(window_title=\"Football Manager 2024\"):\n",
    "    # Connect to the Football Manager window by title (regular expression)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        app = Application().connect(title_re=window_title)\n",
    "\n",
    "        # Bring the window to the foreground\n",
    "        app.top_window().set_focus()\n",
    "        print(f\"{window_title} window is now active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate {window_title} window: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccf603-aff3-4b02-b7c7-a2884c4f670a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "navigate_to_fm_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b43afa-f21b-4e96-bfc7-bd53bbdaa6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this in CMD/iPython separate window to diagnose mouse position\n",
    "# import pyautogui\n",
    "# import time\n",
    "\n",
    "# # Continuously display mouse position\n",
    "# try:\n",
    "#     while True:\n",
    "#         x, y = pyautogui.position()\n",
    "#         print(f\"Mouse position: ({x}, {y})\", end=\"\\r\")\n",
    "#         time.sleep(0.1)  # Update every 0.1 seconds\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"\\nStopped displaying mouse position.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d2d2e-b4ee-4c10-8f5a-67f5efa0a07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "navigate_to_fm_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b574d7-90f0-433b-9f62-15406114df84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a sleep duration to allow for navigation\n",
    "SLEEP_DURATION = 2\n",
    "\n",
    "# Define screen resolution\n",
    "screen_width, screen_height = 3840, 2160\n",
    "\n",
    "# Example coordinates for specific areas (adjust these to match your actual screen)\n",
    "# Coordinates are in the form of (x, y)\n",
    "menu_cup_icon_coords = (49, 937)  # Example coordinates for \"cup\" icon\n",
    "zylofon_league_coords = (566, 318)  # Coordinates for Zylofon League\n",
    "matches_results_coords = (1271, 329)  # Coordinates for \"MATCHES/RESULTS>\"\n",
    "\n",
    "\n",
    "# Coordinates for the region where dates appear on the screen (adjust these)\n",
    "date_region = (2510, 225, 793, 58)  # Example coordinates (x, y, width, height)\n",
    "\n",
    "# Function to navigate to Football Manager 2024 Window\n",
    "def navigate_to_fm_window(window_title=\"Football Manager 2024\"):\n",
    "    # Connect to the Football Manager window by title (regular expression)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    try:\n",
    "        app = Application().connect(title_re=window_title)\n",
    "\n",
    "        # Bring the window to the foreground\n",
    "        app.top_window().set_focus()\n",
    "        print(f\"{window_title} window is now active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate {window_title} window: {e}\")\n",
    "\n",
    "# Click on the \"cup\" icon to go to the Competitions screen\n",
    "def navigate_to_competitions():\n",
    "    pyautogui.click(menu_cup_icon_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"Zylofon Cash Premier League\" link\n",
    "def navigate_to_zylofon_league():\n",
    "    pyautogui.click(zylofon_league_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"MATCHES/RESULTS>\" link\n",
    "def click_matches_results():\n",
    "    pyautogui.click(matches_results_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Example function to capture screen and process text using pytesseract\n",
    "def capture_and_process_screen(region=None):\n",
    "    # Capture the screen (or specific region)\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Use pytesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(screenshot)\n",
    "    print(f\"Extracted text: {text}\")\n",
    "    \n",
    "    # Save the screenshot for debugging if necessary\n",
    "    screenshot.save(\"current_screen.png\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def capture_and_process_date(region=None):\n",
    "    # Capture the screen region\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Save the screenshot for debugging\n",
    "    screenshot.save(\"date_region.png\")\n",
    "    \n",
    "    # Use pytesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(screenshot)\n",
    "    print(f\"Extracted date text: {text}\")\n",
    "    \n",
    "    # Return the extracted text for further processing\n",
    "    return text\n",
    "\n",
    "# Parse the extracted date and time text\n",
    "def parse_date(text):\n",
    "    # Debug: print the original OCR output\n",
    "    print(f\"Original OCR output: '{text}'\")\n",
    "\n",
    "    # Clean up the text by removing unwanted characters like 'v', '<', '>'\n",
    "    cleaned_text = re.sub(r'v|<|>', '', text)\n",
    "\n",
    "    # Debug: print the cleaned text after removing unwanted characters\n",
    "    # print(f\"After removing 'v', '<', '>': '{cleaned_text}'\")\n",
    "\n",
    "    # Remove any extra spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    # Debug: print the cleaned text after normalizing spaces\n",
    "    # print(f\"After normalizing spaces: '{cleaned_text}'\")\n",
    "\n",
    "    # Remove ordinal suffixes ONLY when they appear after a digit (e.g., 1st, 2nd, 3rd, 4th)\n",
    "    cleaned_text = re.sub(r'(\\d)(st|nd|rd|th)', r'\\1', cleaned_text)\n",
    "\n",
    "    # Debug: print the cleaned text after removing ordinal suffixes\n",
    "    # print(f\"After removing ordinal suffixes: '{cleaned_text}'\")\n",
    "\n",
    "    # Attempt to split the cleaned text by the year (assuming year is at the end)\n",
    "    try:\n",
    "        date_part, year_part = cleaned_text.rsplit(\" \", 1)\n",
    "\n",
    "        # Reconstruct the full date string\n",
    "        full_date_text = f\"{date_part} {year_part}\".strip()\n",
    "\n",
    "        # Debug: print the final date string before parsing\n",
    "        # print(f\"Final date string to parse: '{full_date_text}'\")\n",
    "\n",
    "        # Attempt to parse the date\n",
    "        parsed_date = datetime.strptime(full_date_text, \"%A %B %d %Y\")\n",
    "        print(f\"Parsed date: {parsed_date}\")\n",
    "        return parsed_date\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to parse date: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def detect_score_boxes(image_path, roi=None, lower_blue_hsv=None, upper_blue_hsv=None):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Restrict to region of interest (ROI) if provided\n",
    "    if roi:\n",
    "        x, y, w, h = roi\n",
    "        img = img[y:y+h, x:x+w]\n",
    "\n",
    "    # Convert the image to HSV (Hue, Saturation, Value) color space\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for the blue color in HSV\n",
    "    if lower_blue_hsv is None:\n",
    "        lower_blue_hsv = np.array([20, 20, 200], dtype=np.uint8)  # Adjusted lower bound\n",
    "    if upper_blue_hsv is None:\n",
    "        upper_blue_hsv = np.array([40, 60, 255], dtype=np.uint8)  # Adjusted upper bound\n",
    "\n",
    "    # Create a mask for the blue color within the bounds\n",
    "    mask = cv2.inRange(hsv_img, lower_blue_hsv, upper_blue_hsv)\n",
    "\n",
    "    # Find contours (these would be the blue boxes around the scores)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop through detected contours and mark them\n",
    "    for contour in contours:\n",
    "        # Get the bounding box of the contour (x, y, width, height)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Draw a rectangle around detected boxes (optional for visualization)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Crop the detected box\n",
    "        score_box = img[y:y+h, x:x+w]\n",
    "\n",
    "        # Optional: Save the cropped score box for debugging\n",
    "        cv2.imwrite(f\"score_box_{x}_{y}.png\", score_box)\n",
    "\n",
    "    # Save and show the final image with detected boxes\n",
    "    cv2.imwrite(\"final_detected_boxes.png\", img)\n",
    "    cv2.imshow(\"Detected Boxes\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # You can either further process the score_box with OCR or do additional pixel analysis\n",
    "    # Process with pytesseract if needed:\n",
    "    # pil_img = Image.fromarray(score_box)\n",
    "    # text = pytesseract.image_to_string(pil_img)\n",
    "    # print(f\"Extracted score text: {text}\")\n",
    "\n",
    "\n",
    "# Example usage of the navigation and screen capture functions\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 0: Navigate to FM\n",
    "    navigate_to_fm_window()\n",
    "    \n",
    "    # Step 1: Navigate to the Competitions screen\n",
    "    navigate_to_competitions()\n",
    "\n",
    "    # Step 2: Navigate to the Zylofon Cash Premier League\n",
    "    navigate_to_zylofon_league()\n",
    "\n",
    "    # Step 3: Click on \"MATCHES/RESULTS>\"\n",
    "    click_matches_results()\n",
    "\n",
    "    # Step 4: Capture and process the Matches and Results screen\n",
    "\n",
    "    # Capture the region with the date\n",
    "    date_text = capture_and_process_date(region=date_region)\n",
    "    \n",
    "    \n",
    "    # Parse the extracted date text\n",
    "    match_date = parse_date(date_text)\n",
    "    \n",
    "    # print(f\"Match date: {match_date}\")\n",
    "    # capture_and_process_screen(region=(0, 0, screen_width, screen_height))  # Adjust region as needed\n",
    "    capture_and_process_screen(region=(113, 285, 2619, 1811))  # Adjust region as needed\n",
    "\n",
    "    roi = (1423, 280, 399, 1761)\n",
    "    # Example usage\n",
    "    detect_score_boxes(\"current_screen.png\", roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb2f44-738b-457f-bf9b-3a89ec6233ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "blue_rgb = np.uint8([[[255, 255, 152]]])  # Replace with your discovered blue RGB values\n",
    "hsv_blue = cv2.cvtColor(blue_rgb, cv2.COLOR_BGR2HSV)\n",
    "print(\"HSV value for the blue color: \", hsv_blue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb66f8a-f65a-46e5-be71-3e855f537f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football Manager 2024 window is now active.\n"
     ]
    },
    {
     "ename": "TesseractError",
     "evalue": "(3221225781, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTesseractError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m click_matches_results()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Step 4: Capture and process the Matches and Results screen\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m date_text \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_and_process_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_region\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m, in \u001b[0;36mcapture_and_process_date\u001b[1;34m(region)\u001b[0m\n\u001b[0;32m     87\u001b[0m pil_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(processed_img)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Use pytesseract to extract text from the processed image\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Debugging: Save the processed image\u001b[39;00m\n\u001b[0;32m     93\u001b[0m pil_img\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_date_region.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:288\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    278\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    286\u001b[0m     }\n\u001b[1;32m--> 288\u001b[0m     run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:264\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc\u001b[38;5;241m.\u001b[39mreturncode, get_errors(error_string))\n",
      "\u001b[1;31mTesseractError\u001b[0m: (3221225781, '')"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "from pywinauto.application import Application\n",
    "\n",
    "# Set a sleep duration to allow for navigation\n",
    "SLEEP_DURATION = 2\n",
    "\n",
    "# Define screen resolution\n",
    "screen_width, screen_height = 3840, 2160\n",
    "\n",
    "# Example coordinates for specific areas (adjust these to match your actual screen)\n",
    "menu_cup_icon_coords = (49, 937)  # Example coordinates for \"cup\" icon\n",
    "zylofon_league_coords = (566, 318)  # Coordinates for Zylofon League\n",
    "matches_results_coords = (1271, 329)  # Coordinates for \"MATCHES/RESULTS>\"\n",
    "\n",
    "# Coordinates for the region where dates appear on the screen (adjust these)\n",
    "date_region = (2510, 225, 793, 58)  # Example coordinates (x, y, width, height)\n",
    "\n",
    "# Function to navigate to Football Manager 2024 Window\n",
    "def navigate_to_fm_window(window_title=\"Football Manager 2024\"):\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    try:\n",
    "        app = Application().connect(title_re=window_title)\n",
    "        app.top_window().set_focus()\n",
    "        print(f\"{window_title} window is now active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate {window_title} window: {e}\")\n",
    "\n",
    "# Click on the \"cup\" icon to go to the Competitions screen\n",
    "def navigate_to_competitions():\n",
    "    pyautogui.click(menu_cup_icon_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"Zylofon Cash Premier League\" link\n",
    "def navigate_to_zylofon_league():\n",
    "    pyautogui.click(zylofon_league_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"MATCHES/RESULTS>\" link\n",
    "def click_matches_results():\n",
    "    pyautogui.click(matches_results_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Preprocess the image for better OCR accuracy using OpenCV\n",
    "def preprocess_image_for_ocr(image):\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to enhance contrast\n",
    "    processed_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                          cv2.THRESH_BINARY, 11, 2)\n",
    "    return processed_img\n",
    "\n",
    "# Capture and preprocess the screen for OCR\n",
    "def capture_and_process_screen(region=None):\n",
    "    # Capture the screen (or specific region)\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Convert the screenshot to OpenCV format and preprocess\n",
    "    processed_img = preprocess_image_for_ocr(screenshot)\n",
    "    \n",
    "    # Convert processed image back to PIL format for pytesseract\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    \n",
    "    # Use pytesseract to extract text from the preprocessed image\n",
    "    text = pytesseract.image_to_string(pil_img)\n",
    "    \n",
    "    # Debugging: Save the processed image\n",
    "    pil_img.save(\"processed_screen.png\")\n",
    "    \n",
    "    print(f\"Extracted text: {text}\")\n",
    "    return text\n",
    "\n",
    "# Capture and preprocess the region for date extraction\n",
    "def capture_and_process_date(region=None):\n",
    "    # Capture the screen region\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Convert the screenshot to OpenCV format and preprocess\n",
    "    processed_img = preprocess_image_for_ocr(screenshot)\n",
    "    \n",
    "    # Convert processed image back to PIL format for pytesseract\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    \n",
    "    # Use pytesseract to extract text from the processed image\n",
    "    text = pytesseract.image_to_string(pil_img)\n",
    "    \n",
    "    # Debugging: Save the processed image\n",
    "    pil_img.save(\"processed_date_region.png\")\n",
    "    \n",
    "    print(f\"Extracted date text: {text}\")\n",
    "    return text\n",
    "\n",
    "# Example usage of the navigation and screen capture functions\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 0: Navigate to FM\n",
    "    navigate_to_fm_window()\n",
    "    \n",
    "    # Step 1: Navigate to the Competitions screen\n",
    "    navigate_to_competitions()\n",
    "\n",
    "    # Step 2: Navigate to the Zylofon Cash Premier League\n",
    "    navigate_to_zylofon_league()\n",
    "\n",
    "    # Step 3: Click on \"MATCHES/RESULTS>\"\n",
    "    click_matches_results()\n",
    "\n",
    "    # Step 4: Capture and process the Matches and Results screen\n",
    "    date_text = capture_and_process_date(region=date_region)\n",
    "    \n",
    "    # Capture and process the results screen (adjust region as needed)\n",
    "    # capture_and_process_screen(region=(113, 285, 2619, 1811))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6334ee-107d-4fdf-87f9-94ffa5ee72bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test capture of match screen per team\n",
    "# Capture and preprocess the screen for OCR\n",
    "def capture_and_process_screen(region=None):\n",
    "    # Capture the screen (or specific region)\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Convert the screenshot to OpenCV format and preprocess\n",
    "    processed_img = preprocess_image_for_ocr(screenshot)\n",
    "    \n",
    "    # Convert processed image back to PIL format for pytesseract\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    \n",
    "    # Use pytesseract to extract text from the preprocessed image\n",
    "    text = pytesseract.image_to_string(pil_img)\n",
    "    \n",
    "    # Debugging: Save the processed image\n",
    "    pil_img.save(\"processed_screen.png\")\n",
    "    \n",
    "    print(f\"Extracted text: {text}\")\n",
    "    return text\n",
    "\n",
    "time.sleep(5)\n",
    "capture_and_process_screen(region=(109, 291, 2858, 1763))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d873ef26-6d72-4663-82de-b997346f5f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football Manager 2024 window is now active.\n"
     ]
    },
    {
     "ename": "TesseractError",
     "evalue": "(3221225781, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTesseractError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 244\u001b[0m\n\u001b[0;32m    241\u001b[0m click_matches_results()\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Step 4: Capture and process the Matches and Results screen\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m date_text \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_and_process_date_with_mss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_region\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m match_date \u001b[38;5;241m=\u001b[39m parse_date(date_text)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Step 5: Capture the entire screen and detect score boxes\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# capture_screen_with_mss(region=(113, 285, 2619, 1811))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 115\u001b[0m, in \u001b[0;36mcapture_and_process_date_with_mss\u001b[1;34m(region)\u001b[0m\n\u001b[0;32m    112\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_region.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Use pytesseract to extract text from the image\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted date text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:288\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    278\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    286\u001b[0m     }\n\u001b[1;32m--> 288\u001b[0m     run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytesseract\\pytesseract.py:264\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc\u001b[38;5;241m.\u001b[39mreturncode, get_errors(error_string))\n",
      "\u001b[1;31mTesseractError\u001b[0m: (3221225781, '')"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mss import mss\n",
    "import time\n",
    "import pyautogui\n",
    "from pywinauto.application import Application\n",
    "import pytesseract\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Set a sleep duration to allow for navigation\n",
    "SLEEP_DURATION = 2\n",
    "\n",
    "# Define screen resolution\n",
    "screen_width, screen_height = 3840, 2160\n",
    "\n",
    "# Example coordinates for specific areas (adjust these to match your actual screen)\n",
    "menu_cup_icon_coords = (49, 937)  # Example coordinates for \"cup\" icon\n",
    "zylofon_league_coords = (566, 318)  # Coordinates for Zylofon League\n",
    "matches_results_coords = (1271, 329)  # Coordinates for \"MATCHES/RESULTS>\"\n",
    "\n",
    "# Coordinates for the region where dates appear on the screen (adjust these)\n",
    "date_region = (2510, 225, 793, 58)  # Example coordinates (x, y, width, height)\n",
    "\n",
    "# Function to navigate to Football Manager 2024 Window\n",
    "def navigate_to_fm_window(window_title=\"Football Manager 2024\"):\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    try:\n",
    "        app = Application().connect(title_re=window_title)\n",
    "        app.top_window().set_focus()\n",
    "        print(f\"{window_title} window is now active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate {window_title} window: {e}\")\n",
    "\n",
    "# Click on the \"cup\" icon to go to the Competitions screen\n",
    "def navigate_to_competitions():\n",
    "    pyautogui.click(menu_cup_icon_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"Zylofon Cash Premier League\" link\n",
    "def navigate_to_zylofon_league():\n",
    "    pyautogui.click(zylofon_league_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"MATCHES/RESULTS>\" link\n",
    "def click_matches_results():\n",
    "    pyautogui.click(matches_results_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Example function to capture screen using OpenCV and mss\n",
    "def capture_screen_with_mss(region=None, save_path=\"current_screen.png\"):\n",
    "    with mss() as sct:\n",
    "        # If a region is defined, capture only that part of the screen\n",
    "        if region:\n",
    "            monitor = {\"top\": region[1], \"left\": region[0], \"width\": region[2], \"height\": region[3]}\n",
    "        else:\n",
    "            # Capture the full screen\n",
    "            monitor = sct.monitors[1]\n",
    "\n",
    "        # Capture the screenshot\n",
    "        screenshot = sct.grab(monitor)\n",
    "\n",
    "        # Convert the screenshot to a numpy array (BGRA format)\n",
    "        img = np.array(screenshot)\n",
    "\n",
    "        # Convert from BGRA to BGR (remove the alpha channel)\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # Save the screenshot as a PNG file\n",
    "        cv2.imwrite(save_path, img_bgr)\n",
    "        \n",
    "# Example function to capture screen using OpenCV and mss with text extraction\n",
    "def capture_screen_with_mss_new(region=None, save_path=\"current_screen.png\", extract_text=False):\n",
    "    with mss() as sct:\n",
    "        # If a region is defined, capture only that part of the screen\n",
    "        if region:\n",
    "            monitor = {\"top\": region[1], \"left\": region[0], \"width\": region[2], \"height\": region[3]}\n",
    "        else:\n",
    "            # Capture the full screen\n",
    "            monitor = sct.monitors[1]\n",
    "\n",
    "        # Capture the screenshot\n",
    "        screenshot = sct.grab(monitor)\n",
    "\n",
    "        # Convert the screenshot to a numpy array (BGRA format)\n",
    "        img = np.array(screenshot)\n",
    "\n",
    "        # Convert from BGRA to BGR (remove the alpha channel)\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # Save the screenshot as a PNG file\n",
    "        cv2.imwrite(save_path, img_bgr)\n",
    "\n",
    "        # If text extraction is requested, process the image for OCR\n",
    "        if extract_text:\n",
    "            # Convert the image to grayscale to improve OCR results\n",
    "            gray_img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Use pytesseract to extract text from the grayscale image\n",
    "            extracted_text = pytesseract.image_to_string(gray_img)\n",
    "            \n",
    "            return extracted_text\n",
    "        \n",
    "        return img_bgr\n",
    "\n",
    "# Function to capture and process the date region using OpenCV and pytesseract\n",
    "def capture_and_process_date_with_mss(region):\n",
    "    # Capture the date region using mss\n",
    "    capture_screen_with_mss(region=region, save_path=\"date_region.png\")\n",
    "\n",
    "    # Load the captured image\n",
    "    img = cv2.imread(\"date_region.png\")\n",
    "\n",
    "    # Use pytesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(f\"Extracted date text: {text}\")\n",
    "\n",
    "    return text\n",
    "\n",
    "# Parse the extracted date and time text\n",
    "def parse_date(text):\n",
    "    print(f\"Original OCR output: '{text}'\")\n",
    "    cleaned_text = re.sub(r'v|<|>', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    cleaned_text = re.sub(r'(\\d)(st|nd|rd|th)', r'\\1', cleaned_text)\n",
    "    try:\n",
    "        date_part, year_part = cleaned_text.rsplit(\" \", 1)\n",
    "        full_date_text = f\"{date_part} {year_part}\".strip()\n",
    "        parsed_date = datetime.strptime(full_date_text, \"%A %B %d %Y\")\n",
    "        print(f\"Parsed date: {parsed_date}\")\n",
    "        return parsed_date\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to parse date: {e}\")\n",
    "        return None\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlap_thresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(\n",
    "            idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0]))\n",
    "        )\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "def detect_score_boxes_with_template(image_path, template_path, threshold=0.9, overlap_thresh=0.3):\n",
    "    # Load the main image and the template image\n",
    "    img = cv2.imread(image_path)\n",
    "    template = cv2.imread(template_path, 0)  # Load template as grayscale\n",
    "\n",
    "    # Convert main image to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get template dimensions\n",
    "    template_h, template_w = template.shape\n",
    "\n",
    "    # Perform template matching\n",
    "    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Get locations where matching exceeds the threshold\n",
    "    loc = np.where(res >= threshold)\n",
    "\n",
    "    boxes = []\n",
    "    for pt in zip(*loc[::-1]):  # Iterate over the match locations\n",
    "        # Create bounding boxes for detected areas\n",
    "        boxes.append([pt[0], pt[1], pt[0] + template_w, pt[1] + template_h])\n",
    "\n",
    "    # Apply non-maximum suppression to eliminate overlapping boxes\n",
    "    boxes = np.array(boxes)\n",
    "    final_boxes = non_max_suppression_fast(boxes, overlap_thresh)\n",
    "\n",
    "    # Draw the final boxes on the image\n",
    "    for (x1, y1, x2, y2) in final_boxes:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Optional: Crop and save the detected box\n",
    "        score_box = img[y1:y2, x1:x2]\n",
    "        cv2.imwrite(f\"score_box_{x1}_{y1}.png\", score_box)\n",
    "\n",
    "    # Save and display the final image with detected boxes\n",
    "    cv2.imwrite(\"final_detected_boxes_template_suppressed.png\", img)\n",
    "\n",
    "    # Optionally, display the image using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def extract_text_from_image(image_path):\n",
    "    # Load the image using OpenCV or PIL\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image for better OCR results (convert to grayscale)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use Tesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(gray_image)\n",
    "    \n",
    "    return extracted_text    \n",
    "\n",
    "# Example usage of the navigation and screen capture functions\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 0: Navigate to FM\n",
    "    navigate_to_fm_window()\n",
    "    \n",
    "    # Step 1: Navigate to the Competitions screen\n",
    "    navigate_to_competitions()\n",
    "\n",
    "    # Step 2: Navigate to the Zylofon Cash Premier League\n",
    "    navigate_to_zylofon_league()\n",
    "\n",
    "    # Step 3: Click on \"MATCHES/RESULTS>\"\n",
    "    click_matches_results()\n",
    "\n",
    "    # Step 4: Capture and process the Matches and Results screen\n",
    "    date_text = capture_and_process_date_with_mss(region=date_region)\n",
    "    match_date = parse_date(date_text)\n",
    "\n",
    "    # Step 5: Capture the entire screen and detect score boxes\n",
    "    # capture_screen_with_mss(region=(113, 285, 2619, 1811))\n",
    "    capture_screen_with_mss_new(region=(113, 285, 2619, 1811))\n",
    "    detect_score_boxes_with_template(\"current_screen.png\", \"score_box_template.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b4ba1b5-c353-43b5-bf0d-0709cad78fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football Manager 2024 window is now active.\n",
      "Team Name: Hearts of Oak SC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Hearts of Oak SC\n",
      "\n",
      "Team Name: Aduana Stars\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Aduana Stars\n",
      "\n",
      "Team Name: Asante Kotoko SC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Asante Kotoko SC\n",
      "\n",
      "Team Name: Berekum Chelsea\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Berekum Chelsea\n",
      "\n",
      "Team Name: Medeama Sporting Club\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Medeama Sporting Club\n",
      "\n",
      "Team Name: Bibiani Gold Stars FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Bibiani Gold Stars FC\n",
      "\n",
      "Team Name: Accra Lions Football Club\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Accra Lions Football Club\n",
      "\n",
      "Team Name: Nsoatreman FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Nsoatreman FC\n",
      "\n",
      "Team Name: Accra Great Olympics\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Accra Great Olympics\n",
      "\n",
      "Team Name: FC Samartex 1996\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_FC Samartex 1996\n",
      "\n",
      "Team Name: Bechem United\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Bechem United\n",
      "\n",
      "Team Name: Karela United FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Karela United FC\n",
      "\n",
      "Team Name: Real Tamale United\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Real Tamale United\n",
      "\n",
      "Team Name: Nations Football Club\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Nations Football Club\n",
      "\n",
      "Team Name: Heart of Lions FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Heart of Lions FC\n",
      "\n",
      "Team Name: Dreams FC (GHA)\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Dreams FC (GHA)\n",
      "\n",
      "Team Name: Legon Cities FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Legon Cities FC\n",
      "\n",
      "Team Name: Bofoakwa Tano FC\n",
      "\n",
      "Extracted date text: Tue 23:00\n",
      "13 Feb 2024\n",
      "\n",
      "Output File: 2024_02_13_Bofoakwa Tano FC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mss import mss\n",
    "import time\n",
    "import pyautogui\n",
    "from pywinauto.application import Application\n",
    "import pytesseract\n",
    "import re\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Set a sleep duration to allow for navigation\n",
    "SLEEP_DURATION = 2\n",
    "\n",
    "# Number of teams\n",
    "num_of_teams = 18\n",
    "\n",
    "# Define screen resolution\n",
    "screen_width, screen_height = 3840, 2160\n",
    "\n",
    "# Example coordinates for specific areas (adjust these to match your actual screen)\n",
    "menu_cup_icon_coords = (49, 937)  # Example coordinates for \"cup\" icon\n",
    "zylofon_league_coords = (476, 317)  # Coordinates for Zylofon League\n",
    "matches_results_coords = (1271, 329)  # Coordinates for \"MATCHES/RESULTS>\"\n",
    "first_league_team_coords = (444, 564) # Coords for first team in league screen\n",
    "team_schedule_coords = (1167, 170) # Coordinates for \"Schedule\" on a team page\n",
    "back_button_coords = (152, 69) # Back button coords\n",
    "match_view_1_coords = (406, 245) # Back button coords\n",
    "match_view_2_coords = (406, 323)\n",
    "match_view_3_coords = (787, 80) # Back button coords\n",
    "print_ok_coords = (2109, 1239) # Print \"OK\" button coords\n",
    "data_dumps_coords = (1547, 1020) # Data_dumps dir file dir (may change)\n",
    "league_team_offset = 53\n",
    "\n",
    "\n",
    "# Coordinates for the region where dates appear on the screen (adjust these)\n",
    "# date_region = (2510, 225, 793, 58)  # Example coordinates (x, y, width, height)\n",
    "date_region = (3199, 41, 205, 71)\n",
    "# Coordinates for the region where dates appear on the screen (adjust these)\n",
    "team_name_region = (555, 29, 1119, 46)  # Example coordinates (x, y, width, height)\n",
    "\n",
    "\n",
    "# Function to navigate to Football Manager 2024 Window\n",
    "def navigate_to_fm_window(window_title=\"Football Manager 2024\"):\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    try:\n",
    "        app = Application().connect(title_re=window_title)\n",
    "        app.top_window().set_focus()\n",
    "        print(f\"{window_title} window is now active.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to activate {window_title} window: {e}\")\n",
    "\n",
    "        \n",
    "# Create generic navigation function\n",
    "def click_on_coords(coords):\n",
    "    pyautogui.click(coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"cup\" icon to go to the Competitions screen\n",
    "def navigate_to_competitions():\n",
    "    pyautogui.click(menu_cup_icon_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"Zylofon Cash Premier League\" link\n",
    "def navigate_to_zylofon_league():\n",
    "    pyautogui.click(zylofon_league_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"MATCHES/RESULTS>\" link\n",
    "def click_matches_results():\n",
    "    pyautogui.click(matches_results_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "# Click on the \"MATCHES/RESULTS>\" link\n",
    "def click_team_schedule():\n",
    "    pyautogui.click(team_schedule_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "\n",
    "def navigate_to_league_team(offset_count=0):\n",
    "    x, y = first_league_team_coords\n",
    "    # print(f\"Offset Count:{offset_count} , Offset{league_team_offset}\")\n",
    "    y = y + (offset_count * league_team_offset)\n",
    "    # print(f\"Moving to x:{x} y:{y}\")\n",
    "    \n",
    "    # pyautogui.click(x, y)\n",
    "    # time.sleep(SLEEP_DURATION)\n",
    "    click_on_coords((x,y))\n",
    "\n",
    "# Navigate to our custom match view\n",
    "def navigate_to_custom_matches_view():\n",
    "    # pyautogui.click(match_view_1_coords)\n",
    "    # time.sleep(SLEEP_DURATION)\n",
    "    # pyautogui.click(match_view_2_coords)\n",
    "    # time.sleep(SLEEP_DURATION)\n",
    "    click_on_coords(match_view_1_coords)\n",
    "    click_on_coords(match_view_2_coords)\n",
    "    click_on_coords(match_view_3_coords)\n",
    "    \n",
    "# Navigate to our custom match view\n",
    "def navigate_to_player_schedule():\n",
    "    pyautogui.press('f10')\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "def back_button():\n",
    "    pyautogui.click(back_button_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "# Example function to capture screen using OpenCV and mss\n",
    "def capture_screen_with_mss(region=None, save_path=\"current_screen.png\"):\n",
    "    with mss() as sct:\n",
    "        # If a region is defined, capture only that part of the screen\n",
    "        if region:\n",
    "            monitor = {\"top\": region[1], \"left\": region[0], \"width\": region[2], \"height\": region[3]}\n",
    "        else:\n",
    "            # Capture the full screen\n",
    "            monitor = sct.monitors[1]\n",
    "\n",
    "        # Capture the screenshot\n",
    "        screenshot = sct.grab(monitor)\n",
    "\n",
    "        # Convert the screenshot to a numpy array (BGRA format)\n",
    "        img = np.array(screenshot)\n",
    "\n",
    "        # Convert from BGRA to BGR (remove the alpha channel)\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # Save the screenshot as a PNG file\n",
    "        cv2.imwrite(save_path, img_bgr)\n",
    "    \n",
    "\n",
    "def capture_and_process_date(region=None):\n",
    "    # Capture the screen region\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Save the screenshot for debugging\n",
    "    screenshot.save(\"date_region.png\")\n",
    "    \n",
    "    # Use pytesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(screenshot)\n",
    "    print(f\"Extracted date text: {text}\")\n",
    "    \n",
    "    # Return the extracted text for further processing\n",
    "    return text\n",
    "    \n",
    "# Function to capture and process the date region using OpenCV and pytesseract\n",
    "def capture_and_process_date_with_mss(region):\n",
    "    # Capture the date region using mss\n",
    "    capture_screen_with_mss(region=region, save_path=\"date_region.png\")\n",
    "\n",
    "    # Load the captured image\n",
    "    img = cv2.imread(\"date_region.png\")\n",
    "\n",
    "    # Use pytesseract to extract text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(f\"Extracted date text: {text}\")\n",
    "\n",
    "    return text\n",
    "\n",
    "# Preprocess the image for better OCR accuracy using OpenCV\n",
    "def preprocess_image_for_ocr(image):\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to enhance contrast\n",
    "    processed_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                          cv2.THRESH_BINARY, 11, 2)\n",
    "    return processed_img\n",
    "\n",
    "def capture_and_process_screen(region=None):\n",
    "    # Capture the screen (or specific region)\n",
    "    screenshot = pyautogui.screenshot(region=region)\n",
    "    \n",
    "    # Convert the screenshot to OpenCV format and preprocess\n",
    "    processed_img = preprocess_image_for_ocr(screenshot)\n",
    "    \n",
    "    # Convert processed image back to PIL format for pytesseract\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    \n",
    "    # Use pytesseract to extract text from the preprocessed image\n",
    "    text = pytesseract.image_to_string(pil_img)\n",
    "    \n",
    "    # Debugging: Save the processed image\n",
    "    pil_img.save(\"processed_screen.png\")\n",
    "    \n",
    "    print(f\"Extracted text: {text}\")\n",
    "    return text\n",
    "\n",
    "# Function to capture and process the date region using OpenCV and pytesseract\n",
    "def capture_and_process_team_name(region=team_name_region):\n",
    "    # Capture the date region using mss\n",
    "    capture_screen_with_mss(region=region, save_path=\"team_name_region.png\")\n",
    "    extracted_text = extract_text_from_image(\"team_name_region.png\")\n",
    "    # print(f\"Extracted Text: {extracted_text}\")\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Load the image using OpenCV or PIL\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image for better OCR results (convert to grayscale)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use Tesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(gray_image)\n",
    "    \n",
    "    return extracted_text    \n",
    "\n",
    "\n",
    "# Parse the extracted date and time text\n",
    "def parse_date(text):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    cleaned_text =  re.sub(r'\\n', ' ', cleaned_text).strip()\n",
    "    try:\n",
    "        time_obj = datetime.strptime(cleaned_text, \"%a %H:%M %d %b %Y\")\n",
    "        return (time_obj.strftime(\"%Y_%m_%d\"))\n",
    "    except ValueError as e:\n",
    "        print(f\"Failed to parse date: {e}\")\n",
    "        return None\n",
    "    \n",
    "def extract_text_from_image(image_path):\n",
    "    # Load the image using OpenCV or PIL\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image for better OCR results (convert to grayscale)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use Tesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(gray_image)\n",
    "    \n",
    "    return extracted_text    \n",
    "\n",
    "def print_match_data_to_file(output_file):\n",
    "    # Click first match in schedule on far right to avoid issues\n",
    "    click_on_coords((2450, 451))\n",
    "    \n",
    "    # Select all matches\n",
    "    pyautogui.hotkey('ctrl', 'a')\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Print all matches to \n",
    "    pyautogui.hotkey('ctrl', 'p')\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Click OK on output dialog\n",
    "    click_on_coords(print_ok_coords)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Move to coords of data_dumps dir\n",
    "    click_on_coords((1547, 1020))\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Double click current location to open the \"data_dumps\" dir\n",
    "    # to actually open dir\n",
    "    pyautogui.doubleClick()\n",
    "    \n",
    "    # Click on the coords for \"Save As\"\n",
    "    click_on_coords((1852, 682))\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Double click in the field to highlight all text\n",
    "    pyautogui.doubleClick()\n",
    "    \n",
    "    # Enter the file name\n",
    "    pyautogui.write(output_file)\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "    # Hit <enter> to OK the save file\n",
    "    pyautogui.press('enter')\n",
    "    time.sleep(SLEEP_DURATION)\n",
    "    \n",
    "# Example usage of the navigation and screen capture functions\n",
    "if __name__ == \"__main__\":\n",
    "    time.sleep(5)\n",
    "    # Step 0: Navigate to FM\n",
    "    navigate_to_fm_window()\n",
    "    \n",
    "    # Hit escape if needed\n",
    "    pyautogui.press('esc')\n",
    "    # Step 1: Navigate to the Competitions screen\n",
    "    # navigate_to_competitions()\n",
    "    click_on_coords(menu_cup_icon_coords)\n",
    "\n",
    "    # Step 2: Navigate to the Zylofon Cash Premier League\n",
    "    # navigate_to_zylofon_league()\n",
    "    click_on_coords(zylofon_league_coords)\n",
    "    \n",
    "    # Step 3: We want to iterate over every team, so we need to calculate \n",
    "    # the size of the region with teams, divide by the number of teams\n",
    "    # in the league.\n",
    "    for i in range(num_of_teams):\n",
    "        navigate_to_league_team(i)\n",
    "        # navigate_to_zylofon_league()\n",
    "        # click_team_schedule()\n",
    "        # back_button()\n",
    "        team_name = capture_and_process_team_name()\n",
    "        print(f\"Team Name: {team_name}\")\n",
    "        if re.search(\".*Aduana.*\", team_name):\n",
    "            navigate_to_player_schedule()\n",
    "        else:\n",
    "            # click_team_schedule()\n",
    "            click_on_coords(team_schedule_coords)\n",
    "\n",
    "        navigate_to_custom_matches_view()\n",
    "        date_text = capture_and_process_date_with_mss(region=date_region)\n",
    "        parsed_date = parse_date(date_text)\n",
    "        # Save our match data to file via CTRL-A, CTRL-P + use Team Name\n",
    "        output_file_name = parsed_date + \"_\"  + team_name\n",
    "        print(f\"Output File: {output_file_name}\")\n",
    "        print_match_data_to_file(output_file_name)\n",
    "\n",
    "        back_button()\n",
    "        back_button()\n",
    "\n",
    "        \n",
    "#     # Step 4: Capture and process the Matches and Results screen\n",
    "#     date_text = capture_and_process_date_with_mss(region=date_region)\n",
    "#     match_date = parse_date(date_text)\n",
    "\n",
    "#     # Step 5: Capture the entire screen and detect score boxes\n",
    "    # capture_screen_with_mss(region=(113, 285, 2619, 1811))\n",
    "    # capture_screen_with_mss_new(region=(113, 285, 2619, 1811))\n",
    "    # detect_score_boxes_with_template(\"current_screen.png\", \"score_box_template.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a8ec14b-6441-4b0d-bb21-80417cbbaa9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "navigate_to_player_schedule()\n",
    "click_on_coords(team_schedule_coords)\n",
    "navigate_to_custom_matches_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b8034-9746-49e2-a856-848cf251895b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Record mouse and keyword actions\n",
    "actions = []\n",
    "\n",
    "def record_actions(duration):\n",
    "    time.sleep(5)\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration:\n",
    "        x, y = pyautogui.position()\n",
    "        actions.append(('move', x, y))\n",
    "        if pyautogui.mouseDown():\n",
    "            actions.append(('click', x, y))\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "record_actions(45) # Record for 10 seconds\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041ffea-5d0a-4cd9-a465-ae6b8ecab167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd1ff1-e2fd-4e5c-a8a1-44958f54a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay actions\n",
    "\n",
    "for action in actions:\n",
    "    if action[0] == 'move':\n",
    "        pyautogui.moveTo(action[1], action[2], duration=0.1)\n",
    "    elif action[0] == 'click':\n",
    "        pyautogui.click(action[1], action[2])\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f9f75-8a68-44bd-9a2c-9c4299f1cc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
